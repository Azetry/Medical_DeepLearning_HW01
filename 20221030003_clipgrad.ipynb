{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "- [transfer-1](https://officeguide.cc/pytorch-transfer-learning-resnet18-classify-mnist-tutorial-examples/)\n",
    "- [transfer-2](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "- [train, val subset](https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets/50544887#50544887)\n",
    "\n",
    "---\n",
    "- [pytorch训练模型时出现nan原因整合](https://blog.csdn.net/ytusdc/article/details/122321907)\n",
    "```\n",
    "5、进行梯度減枝\n",
    "对超出值域范围的梯度进行约束，避免梯度持续大于1，造成梯度爆炸。（没办法规避梯度消失）\n",
    " pytorch 使用 nn.utils.clip_grad_value(parameters, clip_value)．将所有的参数剪裁到［-clip_value , clip_value]。如 clip_value =1,[100,0.1]=>[1,0.1]，该操作会改变梯度的方向\n",
    "使用 nn.utils.clip_grad_norm_ 按照范数大小进行归一化，当参数的范数（ norm_type=2 范数）大于最大值时，则会将其归约到最大值。该方法可以保证梯度的方向是完全一致的，可能会导致梯度值被缩放到特别小（如［100,0.1]=>[1,0.0001])。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pydicom\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, io\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "from package.dataset import DicomDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(tr: torch.Tensor):\n",
    "    infos = {\n",
    "        'min': torch.amin(tr),\n",
    "        'max': torch.amax(tr),\n",
    "        'dtype': tr.dtype,\n",
    "        'size': tr.size()\n",
    "    }\n",
    "\n",
    "    return infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 2022\n",
    "num_epochs = 10\n",
    "conv_threshold = 30\n",
    "\n",
    "lr = 1e4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>FilePath</th>\n",
       "      <th>index</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A175204</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>/DICOM/A175204/00010018</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A122221</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>/DICOM/A122221/00010034</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A54671</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>/DICOM/A54671/00010021</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A31117</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>/DICOM/A31117/00010022</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A653195</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>/DICOM/A653195/00010016</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>A717094</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>/DICOM/A717094/00010022</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>A741758</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>/DICOM/A741758/00010017</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>A646753</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>/DICOM/A646753/00010023</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>A679904</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>/DICOM/A679904/00010020</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>A156039</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>/DICOM/A156039/00010036</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Age  Gender                 FilePath  index  Stage\n",
       "0    A175204   69       0  /DICOM/A175204/00010018      7      1\n",
       "1    A122221   56       0  /DICOM/A122221/00010034     15      1\n",
       "2     A54671   82       0   /DICOM/A54671/00010021      8      1\n",
       "3     A31117   71       1   /DICOM/A31117/00010022     10      1\n",
       "4    A653195   68       0  /DICOM/A653195/00010016      7      1\n",
       "..       ...  ...     ...                      ...    ...    ...\n",
       "156  A717094   80       1  /DICOM/A717094/00010022     11      3\n",
       "157  A741758   54       1  /DICOM/A741758/00010017      9      3\n",
       "158  A646753   75       1  /DICOM/A646753/00010023     12      3\n",
       "159  A679904   62       1  /DICOM/A679904/00010020      9      3\n",
       "160  A156039   62       1  /DICOM/A156039/00010036     17      3\n",
       "\n",
       "[161 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./data/DICOM/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.CenterCrop(50), transforms.Resize(224),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DicomDataset(root=\"./data\", transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('Stage 1', 'Stage 2', 'Stage 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min': tensor(0.),\n",
       " 'max': tensor(258.3909),\n",
       " 'dtype': torch.float32,\n",
       " 'size': torch.Size([3, 224, 224])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "display(dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Length: 129\n",
      "Validation Data Length: 32\n"
     ]
    }
   ],
   "source": [
    "#  Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "print(f\"Train Data Length: { len(train_indices) }\")\n",
    "print(f\"Validation Data Length: { len(val_indices) }\")\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(train_indices),\n",
    "    'val': len(val_indices),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(dataset, batch_size=batch_size, sampler=train_sampler),\n",
    "    'val': DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/azetry/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/azetry/.conda/envs/torch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/azetry/.conda/envs/torch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16_bn', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU(inplace=True)\n",
       "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (39): ReLU(inplace=True)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier[6] = nn.Linear(in_features=4096, out_features=3, bias=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = training_data[0][0].unsqueeze(0)\n",
    "# with torch.no_grad():\n",
    "#     output = model(test)\n",
    "\n",
    "# print(output[0])\n",
    "# print( torch.nn.functional.softmax(output[0], dim=0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataloader, model, loss_fn, optimizer, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    # 儲存最佳參數\n",
    "    prev_acc = 0.0\n",
    "    best_acc = 0.0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # 計算是否收斂和提前結束\n",
    "    count_cont = 0\n",
    "    finish = False\n",
    "\n",
    "    # Level: Epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs-1}:\")\n",
    "        print(\"-\"*8)\n",
    "\n",
    "        # 每次 epoch 都要跑一次 training 和 validation\n",
    "        # Level: Phase (train, val)\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train': model.train()\n",
    "            else: model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 批次讀取資料進行訓練\n",
    "            # Level: Batch Data\n",
    "            for batch, (X, y) in enumerate(dataloader[phase]):\n",
    "                # 將資料放置於 GPU 或 CPU\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                # optimizer.zero_grad() # 重設參數梯度（gradient）\n",
    "\n",
    "                # forward\n",
    "                # 只有在訓練階段才要計算梯度\n",
    "                with torch.set_grad_enabled(phase == 'train'): # phase = True or False\n",
    "                    outputs = model(X)                  # 計算預測值\n",
    "                    _, preds = torch.max(outputs, 1)    # 計算預測結果\n",
    "                    loss = loss_fn(outputs, y)          # 計算損失值（loss）\n",
    "\n",
    "                    # 只有在訓練階段才要優化\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()           # 重設參數梯度（gradient）\n",
    "                        loss.backward()                 # 反向傳播（backpropagation）\n",
    "                        nn.utils.clip_grad_norm(model.parameters(), max_norm=20, norm_type=2) # 梯度剪枝\n",
    "                        optimizer.step()                # 更新參數\n",
    "\n",
    "                # 統計\n",
    "                running_loss += loss.item() * Ｘ.size(0) # Batch size\n",
    "                running_corrects += torch.sum(preds == y.data)\n",
    "            # End of Level: Batch Data\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'train':\n",
    "                if epoch_acc == prev_acc: count_cont += 1\n",
    "                else: count_cont = 0\n",
    "                prev_acc = epoch_acc\n",
    "\n",
    "                if count_cont > conv_threshold: \n",
    "                    print(\"Convergence. Ｅnd training early.\")\n",
    "                    finish = True\n",
    "                    break\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        # End of Level: Phase (train, val)\n",
    "\n",
    "        print(\"-\"*8)\n",
    "        if finish: break\n",
    "    # End of Level: Epoch\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # 載入模型最佳參數\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9:\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1207100/2952392942.py:46: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), max_norm=20, norm_type=2) # 梯度剪枝\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 36733470857200427597824.0000 Acc: 0.3953\n",
      "val Loss: 14220262773965289684992.0000 Acc: 0.3750\n",
      "--------\n",
      "Epoch 1/9:\n",
      "--------\n",
      "train Loss: 125357153412159872.0000 Acc: 0.3333\n",
      "val Loss: 7671780191182836989952.0000 Acc: 0.2812\n",
      "--------\n",
      "Epoch 2/9:\n",
      "--------\n",
      "train Loss: 2102187898145836288.0000 Acc: 0.3566\n",
      "val Loss: 19617767220877117620224.0000 Acc: 0.1562\n",
      "--------\n",
      "Epoch 3/9:\n",
      "--------\n",
      "train Loss: 81647817217.8177 Acc: 0.3566\n",
      "val Loss: 2963793992823158603776.0000 Acc: 0.1875\n",
      "--------\n",
      "Epoch 4/9:\n",
      "--------\n",
      "train Loss: 84866364296264008335360.0000 Acc: 0.3256\n",
      "val Loss: 5301879829043695952330752.0000 Acc: 0.4062\n",
      "--------\n",
      "Epoch 5/9:\n",
      "--------\n",
      "train Loss: 12925304729907612688056320.0000 Acc: 0.2946\n",
      "val Loss: 11640191369984647547060224.0000 Acc: 0.3438\n",
      "--------\n",
      "Epoch 6/9:\n",
      "--------\n",
      "train Loss: 17422895297608890842087424.0000 Acc: 0.2946\n",
      "val Loss: 10807005947341918527553536.0000 Acc: 0.3438\n",
      "--------\n",
      "Epoch 7/9:\n",
      "--------\n",
      "train Loss: 17845934989859230473781248.0000 Acc: 0.3023\n",
      "val Loss: 11451697711180682807476224.0000 Acc: 0.3438\n",
      "--------\n",
      "Epoch 8/9:\n",
      "--------\n",
      "train Loss: 16940992524984366015709184.0000 Acc: 0.3178\n",
      "val Loss: 11728469704901265364877312.0000 Acc: 0.3438\n",
      "--------\n",
      "Epoch 9/9:\n",
      "--------\n",
      "train Loss: 18490048856681438257348608.0000 Acc: 0.3178\n",
      "val Loss: 11064802564464530784518144.0000 Acc: 0.3438\n",
      "--------\n",
      "Training complete in 0m 43s\n",
      "Best val Acc: 0.406250\n"
     ]
    }
   ],
   "source": [
    "model = train_model(dataloaders, model, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練成功但是 loss 太詭異了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"20221030003_clipgrad.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch(azetry)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
