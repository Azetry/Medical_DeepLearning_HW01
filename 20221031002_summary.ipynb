{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pydicom\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, io\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f524948a6b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "np.random.seed(2022)\n",
    "random.seed(2022)\n",
    "torch.manual_seed(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(tr: torch.Tensor):\n",
    "    infos = {\n",
    "        'min': torch.amin(tr),\n",
    "        'max': torch.amax(tr),\n",
    "        'dtype': tr.dtype,\n",
    "        'size': tr.size()\n",
    "    }\n",
    "\n",
    "    return infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "split = .8\n",
    "shuffle_dataset = True\n",
    "random_seed= 2022\n",
    "num_epochs = 10\n",
    "conv_threshold = 30\n",
    "\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPECTDataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    - split data into train, val (frac, 1-frac)\n",
    "    - random_state set 2022 (fix random result)\n",
    "    '''\n",
    "    def __init__(self, root, train, frac, transform):\n",
    "        self.root = Path(root)\n",
    "        self.transform = transform\n",
    "        df = pd.read_csv( str(self.root/ \"DICOM/train.csv\") )\n",
    "\n",
    "        # Train / Validation data\n",
    "        train_df = df.sample(frac=frac, random_state=2022, ignore_index=True)\n",
    "        if train: self.list = train_df\n",
    "        else: self.list = pd.concat( [df, train_df] ).drop_duplicates(keep=False, ignore_index=True)\n",
    "\n",
    "        # edit file path\n",
    "        self.list.FilePath = self.list.FilePath.apply(lambda _: self.root / _[1:])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dcm = pydicom.read_file( str(self.list.FilePath[idx]) )\n",
    "\n",
    "        # age, gender\n",
    "        age = self.list.loc[idx, 'Age']\n",
    "        gender = self.list.loc[idx, 'Gender']\n",
    "        \n",
    "        # label (1,2,3 -> 0.,1,2)\n",
    "        label = int(self.list.Stage[idx]) - 1\n",
    "\n",
    "        # Preprocessed Pixels: totensor, 3 channel\n",
    "        pixel = dcm.pixel_array[ self.list.loc[idx, 'index'] ] # 用 index 當 column name 真的是天才\n",
    "        # low, high = self.get_low_high(dcm)\n",
    "        # pixeled = self.getWindow(pixel, low, high)\n",
    "        # img = (pixeled - np.min(pixeled)) / (np.max(pixeled) - np.min(pixeled))\n",
    "        img = torch.tensor(pixel.astype(np.float32))\n",
    "        img = torch.stack([img, img, img], dim=0)\n",
    "\n",
    "        seed = np.random.randint(1e9)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img, age, gender, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.CenterCrop(50), \n",
    "    # transforms.Normalize((62.2852, 62.2852, 62.2852), (76.8448, 76.8448, 76.8448)), # 跑 normalize 反而下降準確度\n",
    "    transforms.Resize(224),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = SPECTDataset(root=\"./data\", train=True, frac=split, transform=preprocess)\n",
    "validation_data = SPECTDataset(root=\"./data\", train=False, frac=split, transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料集數量： 129\n",
      "測試資料集數量： 32\n"
     ]
    }
   ],
   "source": [
    "print(\"訓練資料集數量：\", len(training_data))\n",
    "print(\"測試資料集數量：\", len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': DataLoader(training_data, batch_size=batch_size, shuffle=shuffle_dataset),\n",
    "    'val': DataLoader(validation_data, batch_size=batch_size, shuffle=shuffle_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([16, 3, 224, 224])\n",
      "Shape of y:  torch.Size([16]) torch.int64\n",
      "Age:  tensor([25, 64, 74, 48, 81, 75, 54, 77, 75, 64, 50, 80, 67, 85, 72, 66])\n",
      "Gender:  tensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for X, age, gender, y in dataloaders['val']:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    print(\"Age: \", age)\n",
    "    print(\"Gender: \", gender)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPECT_VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SPECT_VGG16, self).__init__()\n",
    "\n",
    "        # 載入 VGG16 類神經網路結構\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\n",
    "\n",
    "        # 鎖定 VGG16 預訓練模型參數\n",
    "        for param in self.model.parameters():\n",
    "           param.requires_grad = False\n",
    "\n",
    "        # 修改輸出層輸出數量\n",
    "        self.model.classifier.add_module(\"7\", nn.Linear(in_features=1000, out_features=20))\n",
    "\n",
    "    def forward(self, x, age, gender):\n",
    "        logits_ = self.model(x)\n",
    "\n",
    "        # Add Age and Gender\n",
    "        age.unsqueeze_(1)\n",
    "        logits_ = torch.cat((logits_, age), dim=1)\n",
    "\n",
    "        gender.unsqueeze_(1)\n",
    "        logits_ = torch.cat((logits_, gender), dim=1)\n",
    "\n",
    "        # Final Classifier\n",
    "        logits = nn.Linear(22, 3).to(device)(logits_)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/azetry/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/azetry/.conda/envs/torch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/azetry/.conda/envs/torch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPECT_VGG16(\n",
      "  (model): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace=True)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "      (7): Linear(in_features=1000, out_features=20, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg16 = SPECT_VGG16().to(device)\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPECT_ResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SPECT_ResNet50, self).__init__()\n",
    "\n",
    "        # 載入 ResNet50 類神經網路結構\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "\n",
    "        # 鎖定 ResNet50 預訓練模型參數\n",
    "        for param in self.model.parameters():\n",
    "           param.requires_grad = False\n",
    "\n",
    "        # 修改輸出層輸出數量\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 200),\n",
    "            nn.Linear(200, 20)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, age, gender):\n",
    "        logits_ = self.model(x)\n",
    "\n",
    "        # Add Age and Gender\n",
    "        age.unsqueeze_(1)\n",
    "        logits_ = torch.cat((logits_, age), dim=1)\n",
    "\n",
    "        gender.unsqueeze_(1)\n",
    "        logits_ = torch.cat((logits_, gender), dim=1)\n",
    "\n",
    "        # Final Classifier (這樣寫不太好，但就先可以run)\n",
    "        logits = nn.Linear(22, 3).to(device)(logits_)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/azetry/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/azetry/.conda/envs/torch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/azetry/.conda/envs/torch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPECT_ResNet50(\n",
      "  (model): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=200, bias=True)\n",
      "      (1): Linear(in_features=200, out_features=20, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet50 = SPECT_ResNet50().to(device)\n",
    "print(resnet50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterions = {'vgg16': nn.CrossEntropyLoss(), 'resnet50': nn.CrossEntropyLoss()}\n",
    "optimizers = {\n",
    "    'vgg16': optim.SGD(vgg16.parameters(), lr=lr, momentum=0.9), \n",
    "    'resnet50': optim.SGD(resnet50.parameters(), lr=lr, momentum=0.9)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataloader, model, loss_fn, optimizer, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    # 儲存最佳參數\n",
    "    prev_acc = 0.0\n",
    "    best_acc = 0.0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # 計算是否收斂和提前結束\n",
    "    count_cont = 0\n",
    "    finish = False\n",
    "\n",
    "    # Level: Epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs-1}:\")\n",
    "        print(\"-\"*8)\n",
    "\n",
    "        # 每次 epoch 都要跑一次 training 和 validation\n",
    "        # Level: Phase (train, val)\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train': model.train()\n",
    "            else: model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 批次讀取資料進行訓練\n",
    "            # Level: Batch Data\n",
    "            for batch, (X, age, gender, y) in enumerate(dataloader[phase]):\n",
    "                # 將資料放置於 GPU 或 CPU\n",
    "                X, age, gender, y = X.to(device), age.to(device), gender.to(device), y.to(device)\n",
    "\n",
    "                optimizer.zero_grad() # 重設參數梯度（gradient）\n",
    "\n",
    "                # forward\n",
    "                # 只有在訓練階段才要計算梯度\n",
    "                with torch.set_grad_enabled(phase == 'train'): # phase = True or False\n",
    "                    outputs = model(X, age, gender)                  # 計算預測值\n",
    "                    _, preds = torch.max(outputs, 1)    # 計算預測結果\n",
    "                    loss = loss_fn(outputs, y)          # 計算損失值（loss）\n",
    "\n",
    "                    # 只有在訓練階段才要優化\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()                 # 反向傳播（backpropagation）\n",
    "                        optimizer.step()                # 更新參數\n",
    "\n",
    "                # 統計\n",
    "                running_loss += loss.item() * X.size(0) # Batch size\n",
    "                running_corrects += torch.sum(preds == y.data)\n",
    "            # End of Level: Batch Data\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader[phase].dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'train':\n",
    "                if epoch_acc == prev_acc: count_cont += 1\n",
    "                else: count_cont = 0\n",
    "                prev_acc = epoch_acc\n",
    "\n",
    "                if count_cont > conv_threshold: \n",
    "                    print(\"Convergence. End training early.\")\n",
    "                    finish = True\n",
    "                    break\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        # End of Level: Phase (train, val)\n",
    "\n",
    "        print(\"-\"*8)\n",
    "        if finish: break\n",
    "    # End of Level: Epoch\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # 載入模型最佳參數\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VGG16 ...\n",
      "----------\n",
      "Epoch 0/9:\n",
      "--------\n",
      "train Loss: 11.1596 Acc: 0.3566\n",
      "val Loss: 8.1583 Acc: 0.4688\n",
      "--------\n",
      "Epoch 1/9:\n",
      "--------\n",
      "train Loss: 16.9370 Acc: 0.4264\n",
      "val Loss: 9.4084 Acc: 0.3125\n",
      "--------\n",
      "Epoch 2/9:\n",
      "--------\n",
      "train Loss: 20.3700 Acc: 0.3876\n",
      "val Loss: 35.3675 Acc: 0.2812\n",
      "--------\n",
      "Epoch 3/9:\n",
      "--------\n",
      "train Loss: 24.0774 Acc: 0.3256\n",
      "val Loss: 41.0928 Acc: 0.1875\n",
      "--------\n",
      "Epoch 4/9:\n",
      "--------\n",
      "train Loss: 30.2894 Acc: 0.3023\n",
      "val Loss: 9.4995 Acc: 0.3750\n",
      "--------\n",
      "Epoch 5/9:\n",
      "--------\n",
      "train Loss: 37.4408 Acc: 0.3101\n",
      "val Loss: 22.0148 Acc: 0.2812\n",
      "--------\n",
      "Epoch 6/9:\n",
      "--------\n",
      "train Loss: 33.8830 Acc: 0.3256\n",
      "val Loss: 34.4813 Acc: 0.3125\n",
      "--------\n",
      "Epoch 7/9:\n",
      "--------\n",
      "train Loss: 42.9936 Acc: 0.3953\n",
      "val Loss: 26.7843 Acc: 0.4062\n",
      "--------\n",
      "Epoch 8/9:\n",
      "--------\n",
      "train Loss: 48.8194 Acc: 0.3256\n",
      "val Loss: 8.8365 Acc: 0.3125\n",
      "--------\n",
      "Epoch 9/9:\n",
      "--------\n",
      "train Loss: 30.3256 Acc: 0.2636\n",
      "val Loss: 56.5869 Acc: 0.1875\n",
      "--------\n",
      "Training complete in 0m 9s\n",
      "Best val Acc: 0.468750\n",
      "Completed.\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(\"Training VGG16 ...\")\n",
    "print(\"-\"*10)\n",
    "vgg16 = train_model(dataloaders, vgg16, criterions['vgg16'], optimizers['vgg16'], num_epochs)\n",
    "print(\"Completed.\")\n",
    "print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet50 ...\n",
      "----------\n",
      "Epoch 0/9:\n",
      "--------\n",
      "train Loss: 5.6915 Acc: 0.3411\n",
      "val Loss: 5.7667 Acc: 0.4375\n",
      "--------\n",
      "Epoch 1/9:\n",
      "--------\n",
      "train Loss: 7.9717 Acc: 0.3023\n",
      "val Loss: 9.1142 Acc: 0.2812\n",
      "--------\n",
      "Epoch 2/9:\n",
      "--------\n",
      "train Loss: 7.1057 Acc: 0.4186\n",
      "val Loss: 5.2150 Acc: 0.5938\n",
      "--------\n",
      "Epoch 3/9:\n",
      "--------\n",
      "train Loss: 7.5165 Acc: 0.2713\n",
      "val Loss: 5.7103 Acc: 0.4062\n",
      "--------\n",
      "Epoch 4/9:\n",
      "--------\n",
      "train Loss: 10.2252 Acc: 0.2791\n",
      "val Loss: 8.3661 Acc: 0.1875\n",
      "--------\n",
      "Epoch 5/9:\n",
      "--------\n",
      "train Loss: 7.2387 Acc: 0.2791\n",
      "val Loss: 10.9031 Acc: 0.1875\n",
      "--------\n",
      "Epoch 6/9:\n",
      "--------\n",
      "train Loss: 7.0297 Acc: 0.3333\n",
      "val Loss: 10.9917 Acc: 0.2812\n",
      "--------\n",
      "Epoch 7/9:\n",
      "--------\n",
      "train Loss: 7.5177 Acc: 0.3411\n",
      "val Loss: 3.2979 Acc: 0.3438\n",
      "--------\n",
      "Epoch 8/9:\n",
      "--------\n",
      "train Loss: 9.1437 Acc: 0.3721\n",
      "val Loss: 8.6062 Acc: 0.4688\n",
      "--------\n",
      "Epoch 9/9:\n",
      "--------\n",
      "train Loss: 10.0225 Acc: 0.3333\n",
      "val Loss: 6.5936 Acc: 0.2812\n",
      "--------\n",
      "Training complete in 0m 7s\n",
      "Best val Acc: 0.593750\n",
      "Completed.\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(\"Training ResNet50 ...\")\n",
    "print(\"-\"*10)\n",
    "resnet50 = train_model(dataloaders, resnet50, criterions['resnet50'], optimizers['resnet50'], num_epochs)\n",
    "print(\"Completed.\")\n",
    "print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved.\n"
     ]
    }
   ],
   "source": [
    "torch.save(vgg16, \"20221031002_vgg16.pth\")\n",
    "torch.save(resnet50, \"20221031002_resnet50.pth\")\n",
    "print(\"Saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SPECT_ResNet50(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=200, bias=True)\n",
       "      (1): Linear(in_features=200, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16 = torch.load(\"20221031002_vgg16.pth\")\n",
    "resnet50 = torch.load(\"20221031002_resnet50.pth\")\n",
    "vgg16.eval()\n",
    "resnet50.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/DICOM/test.csv\")\n",
    "df.FilePath = df.FilePath.apply(lambda _: Path(\"./data\") / _[1:])\n",
    "\n",
    "vgg16_df = df.copy()\n",
    "resnet50_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPECTTestDataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    - split data into train, val (frac, 1-frac)\n",
    "    - random_state set 2022 (fix random result)\n",
    "    '''\n",
    "    def __init__(self, root, transform):\n",
    "        self.root = Path(root)\n",
    "        self.transform = transform\n",
    "        self.list = pd.read_csv( str(self.root/ \"DICOM/test.csv\") )\n",
    "\n",
    "        # edit file path\n",
    "        self.list.FilePath = self.list.FilePath.apply(lambda _: self.root / _[1:])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dcm = pydicom.read_file( str(self.list.FilePath[idx]) )\n",
    "\n",
    "        # age, gender\n",
    "        age = self.list.loc[idx, 'Age']\n",
    "        gender = self.list.loc[idx, 'Gender']\n",
    "\n",
    "        # Preprocessed Pixels: totensor, 3 channel\n",
    "        pixel = dcm.pixel_array[ self.list.loc[idx, 'index'] ] # 用 index 當 column name 真的是天才\n",
    "        # low, high = self.get_low_high(dcm)\n",
    "        # pixeled = self.getWindow(pixel, low, high)\n",
    "        # img = (pixeled - np.min(pixeled)) / (np.max(pixeled) - np.min(pixeled))\n",
    "        img = torch.tensor(pixel.astype(np.float32))\n",
    "        img = torch.stack([img, img, img], dim=0)\n",
    "\n",
    "        seed = np.random.randint(1e9)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img, age, gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = SPECTTestDataset(root=\"./data\", transform=preprocess)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = (\"Stage 1\",\"Stage 2\",\"Stage 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG Model State: Eval\n",
      "0:\n",
      "Age: tensor([64], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "1:\n",
      "Age: tensor([72], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "2:\n",
      "Age: tensor([89], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "3:\n",
      "Age: tensor([44], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "4:\n",
      "Age: tensor([72], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "5:\n",
      "Age: tensor([56], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "6:\n",
      "Age: tensor([74], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "7:\n",
      "Age: tensor([71], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "8:\n",
      "Age: tensor([79], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "9:\n",
      "Age: tensor([39], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "10:\n",
      "Age: tensor([65], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "11:\n",
      "Age: tensor([72], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "12:\n",
      "Age: tensor([86], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "13:\n",
      "Age: tensor([60], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "14:\n",
      "Age: tensor([39], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "15:\n",
      "Age: tensor([72], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "16:\n",
      "Age: tensor([59], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "17:\n",
      "Age: tensor([82], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "18:\n",
      "Age: tensor([73], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "19:\n",
      "Age: tensor([47], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "20:\n",
      "Age: tensor([63], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "21:\n",
      "Age: tensor([43], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "22:\n",
      "Age: tensor([54], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "23:\n",
      "Age: tensor([73], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "24:\n",
      "Age: tensor([68], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "25:\n",
      "Age: tensor([72], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "26:\n",
      "Age: tensor([73], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "27:\n",
      "Age: tensor([77], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "28:\n",
      "Age: tensor([74], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "29:\n",
      "Age: tensor([63], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "30:\n",
      "Age: tensor([68], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "31:\n",
      "Age: tensor([76], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "32:\n",
      "Age: tensor([38], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "33:\n",
      "Age: tensor([82], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "34:\n",
      "Age: tensor([85], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "35:\n",
      "Age: tensor([82], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "36:\n",
      "Age: tensor([82], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "37:\n",
      "Age: tensor([62], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "38:\n",
      "Age: tensor([54], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "39:\n",
      "Age: tensor([78], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "40:\n",
      "Age: tensor([69], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# because batch size = 1, each batch == each case\n",
    "with torch.no_grad():\n",
    "    if vgg16.training: print(\"VGG Model State: Train\")\n",
    "    else: print(\"VGG Model State: Eval\")\n",
    "    for batch, (X, age, gender) in enumerate(test_loader):\n",
    "        print(f\"{batch}:\")\n",
    "        X, age, gender = X.to(device), age.to(device), gender.to(device) # 移至 gpu 計算\n",
    "        print(f\"Age: {age}, Gender: {gender}\")\n",
    "        \n",
    "        logits = vgg16(X, age, gender)      # 計算預測值\n",
    "        # 計算預測結果\n",
    "        _, pred = torch.max(logits, 1)\n",
    "        pred = pred[0]\n",
    "        # 計算各預測機率\n",
    "        probs = nn.functional.softmax(logits, dim=1)\n",
    "        probs = probs[0].cpu().numpy()\n",
    "        print(f\"Stage: {stages[pred]}\")\n",
    "        print(\"-\"*10)\n",
    "\n",
    "        # 更新至 dataframe\n",
    "        vgg16_df.loc[batch, \"Stage 1\"] = probs[0]\n",
    "        vgg16_df.loc[batch, \"Stage 2\"] = probs[1]\n",
    "        vgg16_df.loc[batch, \"Stage 3\"] = probs[2]\n",
    "        vgg16_df.loc[batch, \"Stage\"] = stages[pred]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG Model State: Eval\n",
      "0:\n",
      "Age: tensor([64], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "1:\n",
      "Age: tensor([72], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "2:\n",
      "Age: tensor([89], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "3:\n",
      "Age: tensor([44], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "4:\n",
      "Age: tensor([72], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "5:\n",
      "Age: tensor([56], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "6:\n",
      "Age: tensor([74], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "7:\n",
      "Age: tensor([71], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "8:\n",
      "Age: tensor([79], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "9:\n",
      "Age: tensor([39], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "10:\n",
      "Age: tensor([65], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "11:\n",
      "Age: tensor([72], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "12:\n",
      "Age: tensor([86], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "13:\n",
      "Age: tensor([60], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "14:\n",
      "Age: tensor([39], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "15:\n",
      "Age: tensor([72], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "16:\n",
      "Age: tensor([59], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "17:\n",
      "Age: tensor([82], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "18:\n",
      "Age: tensor([73], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "19:\n",
      "Age: tensor([47], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "20:\n",
      "Age: tensor([63], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "21:\n",
      "Age: tensor([43], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "22:\n",
      "Age: tensor([54], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "23:\n",
      "Age: tensor([73], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "24:\n",
      "Age: tensor([68], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "25:\n",
      "Age: tensor([72], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "26:\n",
      "Age: tensor([73], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "27:\n",
      "Age: tensor([77], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "28:\n",
      "Age: tensor([74], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "29:\n",
      "Age: tensor([63], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "30:\n",
      "Age: tensor([68], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "31:\n",
      "Age: tensor([76], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "32:\n",
      "Age: tensor([38], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "33:\n",
      "Age: tensor([82], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "34:\n",
      "Age: tensor([85], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "35:\n",
      "Age: tensor([82], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "36:\n",
      "Age: tensor([82], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 2\n",
      "----------\n",
      "37:\n",
      "Age: tensor([62], device='cuda:0'), Gender: tensor([0], device='cuda:0')\n",
      "Stage: Stage 1\n",
      "----------\n",
      "38:\n",
      "Age: tensor([54], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "39:\n",
      "Age: tensor([78], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n",
      "40:\n",
      "Age: tensor([69], device='cuda:0'), Gender: tensor([1], device='cuda:0')\n",
      "Stage: Stage 3\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# because batch size = 1, each batch == each case\n",
    "with torch.no_grad():\n",
    "    if resnet50.training: print(\"VGG Model State: Train\")\n",
    "    else: print(\"VGG Model State: Eval\")\n",
    "    for batch, (X, age, gender) in enumerate(test_loader):\n",
    "        print(f\"{batch}:\")\n",
    "        X, age, gender = X.to(device), age.to(device), gender.to(device) # 移至 gpu 計算\n",
    "        print(f\"Age: {age}, Gender: {gender}\")\n",
    "        \n",
    "        logits = resnet50(X, age, gender)      # 計算預測值\n",
    "        # 計算預測結果\n",
    "        _, pred = torch.max(logits, 1)\n",
    "        pred = pred[0]\n",
    "        # 計算各預測機率\n",
    "        probs = nn.functional.softmax(logits, dim=1)\n",
    "        probs = probs[0].cpu().numpy()\n",
    "        print(f\"Stage: {stages[pred]}\")\n",
    "        print(\"-\"*10)\n",
    "\n",
    "        # 更新至 dataframe\n",
    "        resnet50_df.loc[batch, \"Stage 1\"] = probs[0]\n",
    "        resnet50_df.loc[batch, \"Stage 2\"] = probs[1]\n",
    "        resnet50_df.loc[batch, \"Stage 3\"] = probs[2]\n",
    "        resnet50_df.loc[batch, \"Stage\"] = stages[pred]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_df.to_csv(\"VGG16.csv\")\n",
    "resnet50_df.to_csv(\"ResNet50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fdcc50b8790cd79eba7c7760378c0f44ab97d60599e9e289704406bba2ea7b42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
